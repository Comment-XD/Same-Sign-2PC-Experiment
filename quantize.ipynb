{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad31f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  9235, -12964,   4885],\n",
       "        [  -860, -14927,  13023],\n",
       "        [   361, -12094, -19212]]], dtype=int16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "img = np.random.rand(1, 3, 3)\n",
    "\n",
    "weights = np.random.randn(1, 3, 3)\n",
    "scale = 2 ** 16\n",
    "\n",
    "\n",
    "encoded_weights = encode(weights)\n",
    "encoded_img = encode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47b2635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plain_out shape: (6, 7, 4)\n",
      "rec shape      : (6, 7, 4)\n",
      "max abs error: 0\n",
      "SUCCESS: reconstructed output equals plaintext convolution.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Utility helpers\n",
    "# ----------------------------\n",
    "def split_share(x):\n",
    "    \"\"\"Additive split into two shares: returns (x0, x1) s.t. x0+x1 = x (over integers).\"\"\"\n",
    "    r = np.random.randint(low=np.iinfo(np.int64).min//4, high=np.iinfo(np.int64).max//4, size=x.shape, dtype=np.int64)\n",
    "    x0 = r\n",
    "    x1 = (x.astype(np.int64) - r).astype(np.int64)\n",
    "    return x0, x1\n",
    "\n",
    "def reconstruct(share_pair):\n",
    "    \"\"\"Reconstruct from two shares.\"\"\"\n",
    "    a, b = share_pair\n",
    "    return (a.astype(np.int64) + b.astype(np.int64)).astype(np.int64)\n",
    "\n",
    "# ----------------------------\n",
    "# Plaintext conv2d (naive)\n",
    "# IN: (H, W, Cin)\n",
    "# W: (k, k, Cin, Cout)\n",
    "# returns O: (H, W, Cout)\n",
    "# ----------------------------\n",
    "def plain_conv2d(IN, W, padding=None, stride=1):\n",
    "    IN = IN.astype(np.int64)\n",
    "    W = W.astype(np.int64)\n",
    "    k = W.shape[0]\n",
    "    if padding is None:\n",
    "        padding = (k - 1) // 2\n",
    "    H, W_in, Cin = IN.shape\n",
    "    Cout = W.shape[3]\n",
    "    H_p = H + 2 * padding\n",
    "    W_p = W_in + 2 * padding\n",
    "    inp = np.pad(IN, ((padding,padding),(padding,padding),(0,0)), mode='constant', constant_values=0)\n",
    "    out_h = (H_p - k)//stride + 1\n",
    "    out_w = (W_p - k)//stride + 1\n",
    "    O = np.zeros((out_h, out_w, Cout), dtype=np.int64)\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            patch = inp[i*stride:i*stride+k, j*stride:j*stride+k, :]   # (k,k,Cin)\n",
    "            # multiply with each output filter\n",
    "            # result: sum_{u,v,c} patch[u,v,c] * W[u,v,c,m]\n",
    "            # vectorized over Cout:\n",
    "            # patch[..., None] * W -> (k,k,Cin, Cout)\n",
    "            prod = patch[..., None] * W   # shape (k,k,Cin,Cout)\n",
    "            O[i, j, :] = np.sum(prod, axis=(0,1,2))\n",
    "    return O\n",
    "\n",
    "# ----------------------------\n",
    "# Beaver triple generator for convolution\n",
    "# Inputs:\n",
    "#   IN_shape = (H, W, Cin)\n",
    "#   W_shape  = (k, k, Cin, Cout)\n",
    "# Returns:\n",
    "#   A_sh = (A0, A1) where A shape = IN_shape\n",
    "#   B_sh = (B0, B1) where B shape = W_shape\n",
    "#   C_sh = (C0, C1) where C = conv(A, B) shape = (H, W, Cout)\n",
    "# ----------------------------\n",
    "def generate_beaver_triple_conv(IN_shape, W_shape, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random\n",
    "    H, W_in, Cin = IN_shape\n",
    "    k, k2, Cin_w, Cout = W_shape\n",
    "    assert k == k2 and Cin == Cin_w, \"kernel dims must match input channels\"\n",
    "    # Sample random A and B with the same shapes as X and Y\n",
    "    A = rng.randint(low=-4, high=5, size=IN_shape).astype(np.int64)   # example small range\n",
    "    B = rng.randint(low=-2, high=3, size=W_shape).astype(np.int64)\n",
    "    # Compute C = conv(A, B)\n",
    "    C = plain_conv2d(A, B)   # shape (H, W, Cout)\n",
    "    # split into shares\n",
    "    A_sh = split_share(A)\n",
    "    B_sh = split_share(B)\n",
    "    C_sh = split_share(C)\n",
    "    return A_sh, B_sh, C_sh\n",
    "\n",
    "# ----------------------------\n",
    "# Two-party conv2d online protocol (simulated)\n",
    "# Inputs:\n",
    "#   IN_sh = (IN0, IN1)   each of shape (H,W,Cin)\n",
    "#   W_sh  = (W0, W1)     each of shape (k,k,Cin,Cout)\n",
    "#   triple_sh = (A_sh, B_sh, C_sh) as returned above\n",
    "# Returns:\n",
    "#   out_sh = (O0, O1) additive shares of the convolution output\n",
    "#\n",
    "# Implementation details:\n",
    "#   - Each party computes d_i = IN_i - A_i, e_i = W_i - B_i\n",
    "#   - They \"open\" d = d0 + d1 and e = e0 + e1 (simulated by reconstruct)\n",
    "#   - Compute full Z = C + conv(d, B) + conv(A, e) + conv(d, e)\n",
    "#   - Randomly split Z into shares Z0, Z1 and return them.\n",
    "# Note: In a real protocol you would avoid reconstructing intermediate secrets except the masked diffs d and e;\n",
    "# here this is a simulation of the full protocol.\n",
    "# ----------------------------\n",
    "def two_party_conv2d(IN_sh, W_sh, triple_sh):\n",
    "    IN0, IN1 = IN_sh\n",
    "    W0, W1 = W_sh\n",
    "    A_sh, B_sh, C_sh = triple_sh\n",
    "    A0, A1 = A_sh\n",
    "    B0, B1 = B_sh\n",
    "    C0, C1 = C_sh\n",
    "\n",
    "    # compute local masked differences\n",
    "    d0 = (IN0.astype(np.int64) - A0.astype(np.int64)).astype(np.int64)\n",
    "    d1 = (IN1.astype(np.int64) - A1.astype(np.int64)).astype(np.int64)\n",
    "    e0 = (W0.astype(np.int64) - B0.astype(np.int64)).astype(np.int64)\n",
    "    e1 = (W1.astype(np.int64) - B1.astype(np.int64)).astype(np.int64)\n",
    "\n",
    "    # \"Open\" d and e (in real protocol parties exchange and reconstruct these)\n",
    "    d_open = (d0 + d1).astype(np.int64)\n",
    "    e_open = (e0 + e1).astype(np.int64)\n",
    "    \n",
    "    # Beaver Triple Protocols\n",
    "\n",
    "    # Compute the full Z (plaintext) using the formula:\n",
    "    # Z = C + conv(d_open, B_full) + conv(A_full, e_open) + conv(d_open, e_open)\n",
    "    B_full = (B0 + B1).astype(np.int64)\n",
    "    A_full = (A0 + A1).astype(np.int64)\n",
    "    C_full = (C0 + C1).astype(np.int64)\n",
    "\n",
    "    conv_d_B = plain_conv2d(d_open, B_full)\n",
    "    conv_A_e = plain_conv2d(A_full, e_open)\n",
    "    conv_d_e = plain_conv2d(d_open, e_open)\n",
    "    Z_full = (C_full + conv_d_B + conv_A_e + conv_d_e).astype(np.int64)\n",
    "\n",
    "    # Randomly split Z_full into two shares and return them (simulation of producing local shares)\n",
    "    Z0, Z1 = split_share(Z_full)\n",
    "    return Z0.astype(np.int64), Z1.astype(np.int64)\n",
    "\n",
    "# ----------------------------\n",
    "# Test driver\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(123)\n",
    "\n",
    "    # parameters\n",
    "    H, W_in = 6, 7\n",
    "    Cin = 3\n",
    "    Cout = 4\n",
    "    k = 3\n",
    "\n",
    "    # random test input and weights (small ints to avoid overflow)\n",
    "    IN = np.random.randint(-5, 6, size=(H, W_in, Cin)).astype(np.int64)\n",
    "    W = np.random.randint(-3, 4, size=(k, k, Cin, Cout)).astype(np.int64)\n",
    "\n",
    "    # plaintext conv\n",
    "    plain_out = plain_conv2d(IN, W)\n",
    "\n",
    "    # share input and weights\n",
    "    IN0, IN1 = split_share(IN)\n",
    "    W0, W1 = split_share(W)\n",
    "\n",
    "    # generate Beaver triple for these shapes\n",
    "    A_sh, B_sh, C_sh = generate_beaver_triple_conv(IN.shape, W.shape)\n",
    "\n",
    "    # run two-party protocol (simulated)\n",
    "    O0, O1 = two_party_conv2d((IN0, IN1), (W0, W1), (A_sh, B_sh, C_sh))\n",
    "\n",
    "    # reconstruct and compare\n",
    "    rec = (O0 + O1).astype(np.int64)\n",
    "    print(\"plain_out shape:\", plain_out.shape)\n",
    "    print(\"rec shape      :\", rec.shape)\n",
    "    diff = plain_out - rec\n",
    "    print(\"max abs error:\", np.max(np.abs(diff)))\n",
    "    if np.max(np.abs(diff)) == 0:\n",
    "        print(\"SUCCESS: reconstructed output equals plaintext convolution.\")\n",
    "    else:\n",
    "        print(\"Mismatch detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b01b61bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  43,  50, ..., 158, 152, 148],\n",
       "        [ 16,   0,  18, ..., 123, 119, 122],\n",
       "        [ 25,  16,  49, ..., 118, 120, 109],\n",
       "        ...,\n",
       "        [208, 201, 198, ..., 160,  56,  53],\n",
       "        [180, 173, 186, ..., 184,  97,  83],\n",
       "        [177, 168, 179, ..., 216, 151, 123]],\n",
       "\n",
       "       [[ 62,  46,  48, ..., 132, 125, 124],\n",
       "        [ 20,   0,   8, ...,  88,  83,  87],\n",
       "        [ 24,   7,  27, ...,  84,  84,  73],\n",
       "        ...,\n",
       "        [170, 153, 161, ..., 133,  31,  34],\n",
       "        [139, 123, 144, ..., 148,  62,  53],\n",
       "        [144, 129, 142, ..., 184, 118,  92]],\n",
       "\n",
       "       [[ 63,  45,  43, ..., 108, 102, 103],\n",
       "        [ 20,   0,   0, ...,  55,  50,  57],\n",
       "        [ 21,   0,   8, ...,  50,  50,  42],\n",
       "        ...,\n",
       "        [ 96,  34,  26, ...,  70,   7,  20],\n",
       "        [ 96,  42,  30, ...,  94,  34,  34],\n",
       "        [116,  94,  87, ..., 140,  84,  72]]], shape=(3, 32, 32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data = torchvision.datasets.CIFAR10(\"./data\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "(data[0][0] * 255).long().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b2ef0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,100) (100,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     47\u001b[39m Y0, Y1 = split_shares1(Y)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Online phase (simulated)\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Party 0 computes E0,F0; Party 1 computes E1,F1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m E0 = (\u001b[43mX0\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mA0\u001b[49m).astype(np.int64)\n\u001b[32m     52\u001b[39m E1 = (X1 - A1).astype(np.int64)\n\u001b[32m     53\u001b[39m F0 = (Y0 - B0).astype(np.int64)\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (10,100) (100,10) "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7a9af04",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 2 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     85\u001b[39m e = np.random.randint(-\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, size=W.shape)\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# z = plain_text_Conv2D(f, e, co, k, w, h)\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# z0 = np.random.randint(-5, 5, size=z.shape)\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# z1 = z - z0\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m \n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Run 2PC convolution\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m O_s0, O_s1 = \u001b[43mTwoPC_Conv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIN_s0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIN_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_s0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m O_rec = O_s0 + O_s1\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# print(\"Plaintext Conv2D:\\n\", O_plain)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mTwoPC_Conv2D\u001b[39m\u001b[34m(IN_s0, IN_s1, W_s0, W_s1, f, e, z0, z1, co, k, w, h)\u001b[39m\n\u001b[32m     42\u001b[39m W1_m = W_s1[:, :, :, m]\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Server 0 local share\u001b[39;00m\n\u001b[32m     45\u001b[39m O_s0[i, j, m] = np.sum(\n\u001b[32m     46\u001b[39m     (patch_s0 - f_m) * e_m +\n\u001b[32m     47\u001b[39m     f_m * (patch_s0 - f_m) +\n\u001b[32m     48\u001b[39m     W0_m * patch_s0 +\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[43mz0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     50\u001b[39m )\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Server 1 local share\u001b[39;00m\n\u001b[32m     53\u001b[39m O_s1[i, j, m] = np.sum(\n\u001b[32m     54\u001b[39m     (patch_s1 - f_m) * e_m +\n\u001b[32m     55\u001b[39m     f_m * (patch_s1 - f_m) +\n\u001b[32m     56\u001b[39m     W1_m * patch_s1 +\n\u001b[32m     57\u001b[39m     z1[i, j, m]\n\u001b[32m     58\u001b[39m )\n",
      "\u001b[31mIndexError\u001b[39m: index 1 is out of bounds for axis 2 with size 1"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crypten",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
